To acquire the data, we had to scrape the Bureau of Transportation Statistics website. The site has both yearly and monthly data available on multiple metrics related to flight departures, delays, and cancellations. For our project we wanted to get all the monthly departure data available from 2013-2022 for both Chicago O'Hare and Chicago Midway. Specifically, we wanted to look at the "Departure Delayed %" column of the data tables.

Read in the data. Explored the data to make sure it was consistent and accurate. Dropped unnecessary columns from the data sets. 
```{r}
Ohare <- read.csv("O'Hare_cleaned.csv")
dim(Ohare)
head(Ohare)
tail(Ohare)
Ohare <- Ohare[, -1]

Midway <- read.csv("midway_cleaned.csv")
dim(Midway)
head(Midway)
tail(Midway)
Midway <- Midway[,-1]
```

## Data Exploration - Plots 
```{r}
#Ohare time plot of the differenced series for the delayed monthly departure percentage 
plot.ts(diff(Ohare$Delayed....))

#Midway time plot of the differenced series for the delayed monthly departure percentage 
plot.ts(diff(Midway$Delayed....))
```

## Create Time Series:
```{r}
Ohare.ts <- ts(Ohare$Delayed...., start = c(2013,1), end = c(2022,11), frequency = 12)
Midway.ts <- ts(Midway$Delayed...., start = c(2013,1), end = c(2022,11), frequency = 12)
```

## Plot the Time Series: 
```{r}
plot(Ohare.ts, main = "O'Hare vs Midway", ylim = c(0,60), xlab = "", ylab = "")
lines(Midway.ts, col = "red")
legend("bottomleft", legend = c("O'Hare", "Midway"), col = c("black", "red"), lty = 1)
```

## Partition the data:
```{r}
nValid <- 12
nTrain <- length(Ohare.ts) - nValid
train.Ohare<- window(Ohare.ts, start = c(2013,1), end = c(2013,nTrain))
valid.Ohare <- window(Ohare.ts, start=c(2013, nTrain+1), end = c(2013, nTrain+nValid))
valid.Ohare
```

```{r}
nValid <- 12
nTrain <- length(Midway.ts) - nValid
train.Midway <- window(Midway.ts, start = c(2013,1), end = c(2013,nTrain))
valid.Midway <- window(Midway.ts, start=c(2013, nTrain+1), end = c(2013, nTrain+nValid))
valid.Midway
```

## Check for a random walk: 
**Indications of a random walk:**
**1) Auto correlations of the differenced series are close to zero.**
**2) The coefficient of AR1 component is close to 1.**

```{r}
library(forecast)
library(zoo)

# Ohare check
Acf(Ohare.ts)
Acf(diff(Ohare.ts))  

# Midway check
Acf(Midway.ts)
Acf(diff(Midway.ts))  
```

Based on these plots, it appears that both the delayed departure percentages for Chicago O'Hare & Midway are not random walks. 

```{r}
fit_Ohare <-Arima(Ohare$Delayed...., order=c(1,0,0))
summary(fit_Ohare)  # ( 0.7088 - 1 ) / 0.0637 = -4.571429

fit_Midway <-Arima(Midway$Delayed...., order=c(1,0,0))
summary(fit_Midway)  # ( 0.7482 - 1 ) /  0.0593 = -4.246206
```

Looking at the AR1 and standard errors for both O'Hare and Midway, we are able to validate the data was not a random walk. 

## Regression-based model(s)

First, lets evaluate all regression based models on the Chicago O'Hare delayed departure percentage dataset.

**Ohare**
```{r}
linear_mod_Ohare <- tslm(train.Ohare ~ trend)
summary(linear_mod_Ohare)
head(linear_mod_Ohare$fitted.values, 12)

linear_season_Ohare <- tslm(train.Ohare ~ trend + season)
summary(linear_season_Ohare)
head(linear_season_Ohare$fitted.values, 12)
```

```{r}
linear_mod_Ohare_pred <- forecast(linear_mod_Ohare, h=nValid, level = 0)
linear_season_Ohare_pred <- forecast(linear_season_Ohare, h=nValid)
plot(linear_mod_Ohare_pred, include = 12)
lines(linear_season_Ohare_pred$mean, col = 'green', lwd = 2)
lines(valid.Ohare)
legend("topleft", legend = c("Actual", "Seasonal", "Linear"),
       col = c("black", "green", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this forecast, we see that seasonal linear regression model performs better when taking into consideration trend and seasonality as opposed to the linear regression model that only considers trend. Therefore, we should drop linear_mod_Ohare and continue evaluating other regression based models in comparison to linear_season_Ohare.

**We now consider poly_season_Ohare that captures seasonality and polynomial trend**
```{r}
options(scipen = 999)
poly_season_Ohare <- tslm(train.Ohare ~ trend + I(trend^2)+ season)
summary(poly_season_Ohare)
```

**Let's look at the forecasts generated by poly_season_Ohare in comparison to the benchmark naive**
```{r}
poly_season_Ohare_pred <- forecast(poly_season_Ohare, h= nValid, level = 0)
snaive_Ohare_pred <- snaive(train.Ohare, h=nValid, level = 0)

plot(poly_season_Ohare_pred, include = 12)
lines(linear_season_Ohare_pred$mean, col = 'red', lwd = 2)
lines(snaive_Ohare_pred$mean, col = 'green', lwd = 2)
lines(valid.Ohare)
legend("topleft", legend = c("Actual", "Seasonal", "Naive", "Poly"),
       col = c("black", "red", "green", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this forecast, it appears that after the Naive method, the polynomial seasonal regression model performs better than the linear seasonal regression model.

Next, let's evaluate whether the exponential seasonal regression model can outperform the polynomial seasonal regression model.
```{r}
exp_season_Ohare <- tslm(train.Ohare ~ trend + season, lambda = 0) 
summary(exp_season_Ohare)
exp_season_Ohare_pred <- forecast(exp_season_Ohare, h= nValid, level=0)
plot(exp_season_Ohare_pred, include = 12)
lines(poly_season_Ohare_pred$mean, col = 'red')
lines(snaive_Ohare_pred$mean, col = 'green')
lines(valid.Ohare)
legend("topleft", legend = c("Actual", "Poly", "Naive", "Exp"),
       col = c("black", "red", "green", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this plot, we can assume that the polynomial seasonal regression model performs best on the Chicago O'Hare data. 

To prove this, lets compare all regression based models accuracy to the benchmark seasonal naive method.

**Compute RMSE, MAE, MAPE using accuracy() to find best **
```{r}
accuracy(linear_season_Ohare_pred$mean, valid.Ohare)  
accuracy(poly_season_Ohare_pred$mean, valid.Ohare)   # Best Performing Regression-based Model
accuracy(exp_season_Ohare_pred$mean, valid.Ohare)
accuracy(snaive_Ohare_pred$mean, valid.Ohare)  
```


Now, lets evaluate all regression based models on Chicago Midway's delayed departure percentage dataset. 

**Midway**
```{r}
linear_mod_Midway <- tslm(train.Midway ~ trend)
summary(linear_mod_Midway)
head(linear_mod_Midway$fitted.values, 12)

linear_season_Midway <- tslm(train.Midway ~ trend + season)
summary(linear_season_Midway)
head(linear_season_Midway$fitted.values, 12)
```

```{r}
linear_mod_Midway_pred <- forecast(linear_mod_Midway, h=nValid, level = 0)
linear_season_Midway_pred <- forecast(linear_season_Midway, h=nValid)
plot(linear_mod_Midway_pred, include = 12)
lines(linear_season_Midway_pred$mean, col = 'green', lwd = 2)
lines(valid.Midway)
legend("topleft", legend = c("Actual", "Seasonal", "Linear"),
       col = c("black", "green", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this forecast, we see that the seasonal linear regression model performs better when taking into consideration trend and seasonality as opposed to the linear regression model that only considers trend. Therefore, we should drop linear_mod_Midway and continue evaluating other regression based models in comparison to linear_season_Midway.

**We now consider poly_season_Midway that capture seasonality and polynomial trend**
```{r}
options(scipen = 999)
poly_season_Midway <- tslm(train.Midway ~ trend + I(trend^2)+ season)
summary(poly_season_Midway)
```

**Let's look at the forecasts generated by poly_season_Midway in comparison to benchmark naive**
```{r}
poly_season_Midway_pred <- forecast(poly_season_Midway, h= nValid, level = 0)
snaive_Midway_pred <- snaive(train.Midway, h=nValid, level = 0)

plot(poly_season_Midway_pred, include = 12)
lines(linear_season_Midway_pred$mean, col = 'red', lwd = 2)
lines(snaive_Midway_pred$mean, col = 'green', lwd = 2)
lines(valid.Midway)
legend("topleft", legend = c("Actual", "Seasonal", "Naive", "Poly"),
       col = c("black", "red", "green", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this forecast, it appears that after the Naive method, the polynomial seasonal regression model performs better than the linear seasonal regression model.

Next, let's evaluate whether the exponential seasonal regression model can outperform the polynomial seasonal regression model.
```{r}
exp_season_Midway <- tslm(train.Midway ~ trend + season, lambda = 0) 
summary(exp_season_Midway)
exp_season_Midway_pred <- forecast(exp_season_Midway, h= nValid, level=0)
plot(exp_season_Midway_pred, include = 12)
lines(poly_season_Midway_pred$mean, col = 'red')
lines(snaive_Midway_pred$mean, col = 'green')
lines(valid.Midway)
legend("topleft", legend = c("Actual", "Poly", "Naive", "Exp"),
       col = c("black", "red", "green", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this plot, we can assume that the polynomial seasonal regression model performs best on the Chicago O'Hare data. 

To prove this, lets compare all regression based models accuracy to the benchmark seasonal naive method.

**Compute RMSE, MAE, MAPE using accuracy() to find best**
```{r}
accuracy(linear_season_Midway_pred$mean, valid.Midway)  
accuracy(poly_season_Midway_pred$mean, valid.Midway)  ## Best Performing Regression-based Model
accuracy(exp_season_Midway_pred$mean, valid.Midway)
accuracy(snaive_Midway_pred$mean, valid.Midway)      
```


---------------------------------------------------------------------------------------------------------------

## Smoothing method(s)

Next, let's evaluate smoothing methods on the Chicago O'Hare and Midway delayed departure percentage datasets.

**Ohare**

**Run Holt-Winters exponential smoothing**

First, we use ets() with option model = "ANA" to fit Holt-Winter's exponential smoothing with multiplicative error, additive trend, and additive seasonality. 
```{r}
hwin <- ets(train.Ohare, model = "ANA")

# Create predictions
hwin.pred <- forecast(hwin, h = nValid, level = 0)
hw.pred <- hw(train.Ohare, h=nValid)
```

```{r}
plot(hwin.pred,  ylab = "Delayed %", xlab = "Time", 
     bty = "l", xaxt = "n", main = "", flty = 2)
axis(1, at = seq(2013, 2025, 1), labels = format(seq(2013, 2025, 1)))
lines(hwin.pred$fitted, lwd = 2, col = "blue")
lines(valid.Ohare)
legend("bottomleft", legend = c("Actual", "Hwin"),
       col = c("black", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)

```

```{r}
ets.aaa <- ets(train.Ohare, model = 'AAA')
ets.aaa.pred <- forecast(ets.aaa, h=nValid, level = 0)
plot(ets.aaa.pred, include = 12)
lines(hw.pred$mean, col = 'red',lwd=2)
lines(valid.Ohare)
```

```{r}
ses.pred <- ses(train.Ohare, h=nValid)
ets.ann <- ets(train.Ohare, model='ANN')
ets.ann.pred <- forecast(ets.ann,h=nValid, level = 0)
```

```{r}
plot(linear_season_Ohare_pred, include= 12, main = "Looking at Holt-Winter")                  
lines(snaive_Ohare_pred$mean,col = 'red', lwd=2)            
lines(hw.pred$mean, col ='green', lwd=2)
lines(valid.Ohare)
legend("bottomleft", legend = c("Actual", "Hwin", "Naive", "linear"),
       col = c("black", "green", "red", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)



plot(hwin.pred, include = 12, main = "Looking at Holt-Winter")
lines(ets.aaa.pred$mean, col = 'red', lwd = 2)
lines(ses.pred$mean, col = 'green', lwd = 2)
lines(valid.Ohare)
legend("topleft", legend = c("Actual", "ets(AAA)", "ses", "hwin(ANA)"),
       col = c("black", "red", "green", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this plot, we can assume that the Holt-Winter smoothing method performs best on the Chicago O'Hare data. 

To prove this, lets compare all of the above smoothing methods accuracy to the benchmark seasonal naive method.

**Compute RMSE, MAE, MAPE using accuracy() to find best**
```{r}
accuracy(hw.pred$mean, valid.Ohare)
accuracy(hwin.pred$mean, valid.Ohare)  
accuracy(ses.pred$mean, valid.Ohare)
accuracy(ets.aaa.pred$mean,valid.Ohare)    ## Best Performing Smoothing Method
accuracy(ets.ann.pred$mean, valid.Ohare)
```

After running the accuracies, it is clear that in fact the ETS(AAA) smoothing method performs the best on the Chicago O'Hare dataset.


Now, lets evaluate smoothing methods on Chicago Midway's delayed departure percentage dataset. 

**Midway**

**Run Holt-Winters exponential smoothing**

Again, we first use ets() with option model = "ANA" to fit Holt-Winter's exponential smoothing with multiplicative error, additive trend, and additive seasonality. 
```{r}
hwin2 <- ets(train.Midway, model = "ANA")
hwin.pred2 <- forecast(hwin2, h = nValid, level = 0)
hw.pred2 <- hw(train.Midway, h=nValid)
```

```{r}
plot(hwin.pred2,  ylab = "Delayed %", xlab = "Time", 
     bty = "l", xaxt = "n", main = "", flty = 2)
axis(1, at = seq(2013, 2025, 1), labels = format(seq(2013, 2025, 1)))
lines(hwin.pred2$fitted, lwd = 2, col = "blue")
lines(valid.Midway)
legend("bottomleft", legend = c("Actual", "Hwin"),
       col = c("black", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

```{r}
ets.aaa2 <- ets(train.Midway, model = 'AAA')
ets.aaa.pred2 <- forecast(ets.aaa2, h=nValid, level = 0)
plot(ets.aaa.pred2, include = 12)
lines(hw.pred2$mean, col = 'red',lwd=2)
lines(valid.Midway)
```

```{r}
ses.pred2 <- ses(train.Midway, h=nValid)
ets.ann2 <- ets(train.Midway, model='ANN')
ets.ann.pred2 <- forecast(ets.ann2,h=nValid, level = 0)
```

**Plot all three forecasts**
```{r}
plot(linear_season_Midway_pred, include= 12, main = "Looking at Holt-Winter")
lines(snaive_Midway_pred$mean,col = 'red', lwd=2)
lines(hw.pred2$mean, col ='green', lwd=2)
lines(valid.Midway)
legend("bottomleft", legend = c("Actual", "Hwin", "Naive", "Linear"),
       col = c("black", "green", "red", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)



plot(hwin.pred2, include = 12, main = "Looking at Holt-Winter")
lines(ets.aaa.pred2$mean, col = 'red', lwd = 2)
lines(ses.pred2$mean, col = 'green', lwd = 2)
lines(valid.Midway)
legend("topleft", legend = c("Actual", "ets(AAA)", "ses", "hwin(ANA)"),
       col = c("black", "red", "green", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this plot, we can assume that the Holt-Winter smoothing method performs best on the Chicago Midway data. 

To prove this, lets compare all of the above smoothing methods accuracy to the benchmark seasonal naive method.

**Compute RMSE, MAE, MAPE using accuracy() to find best**
```{r}
accuracy(hwin.pred2$mean, valid.Midway)   ## Best Performing Smoothing Method
accuracy(hw.pred2$mean, valid.Midway)   
accuracy(ets.aaa.pred2$mean,valid.Midway)
accuracy(ses.pred2$mean, valid.Midway)
accuracy(snaive_Midway_pred$mean, valid.Midway)
```

The accuracy function reinforces our finding that the Holt-Winter smoothing method is indeed the most effective smoothing method on the Chicago Midway dataset. 


------------------------------------------------------------------------------------------------------------

## ARIMA model(s) 

Let's consider ARIMA models on our Chicago delayed departure percentage datasets. 

```{r}
arima.Ohare <- auto.arima(train.Ohare)
summary(arima.Ohare)
arima.Ohare.pred <- forecast(arima.Ohare, h=nValid, level=0)
head(arima.Ohare.pred$mean)
```

```{r}
hwin.R <- ets(train.Ohare)
summary(hwin.R)
hwin.R.pred <- forecast(hwin.R, h=nValid, level=0)
```

```{r}
plot(poly_season_Ohare_pred, include = 12, main = "Comparing ARIMA")   
lines(hw.pred$mean, col = 'purple', lwd = 2)
lines(snaive_Ohare_pred$mean, col = 'green', lwd=2)
lines(arima.Ohare.pred$mean, col = 'pink', lwd=2)
lines(hwin.R.pred$mean, col = 'orange', lwd=2)
lines(valid.Ohare, lwd =2)
legend("topleft", legend = c("Actual","HW", "ETS - ANA", "Naive", "ARIMA", "Poly"),
       col = c("black", "purple", "orange", "green", "pink", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)
```

From this plot, it appears that the Holt-Winter method continues to perform best on the Chicago O'Hare data. The ARIMA model is an improvement over the linear regressions, but might not be as accurate as the Holt-Winter methods.

To prove this, lets compare all of the best methods from regression, smoothing, and ARIMA models by their accuracy to the benchmark seasonal naive method.

```{r}
accuracy(poly_season_Ohare_pred$mean, valid.Ohare) 
accuracy(hwin.pred$mean, valid.Ohare)                   
accuracy(arima.Ohare.pred$mean, valid.Ohare)
accuracy(snaive_Ohare_pred$mean, valid.Ohare)
```

The accuracy function reinforces our previous finding that the Holt-Winter method is indeed the most effective method thus far on the Chicago O'Hare dataset. 


Now, lets apply ARIMA to the Chicago Midway dataset.

```{r}
arima.Midway  <- auto.arima(train.Midway)
summary(arima.Midway)
arima.Midway.pred <- forecast(arima.Midway, h=nValid, level=0)
head(arima.Midway.pred$mean)
```

```{r}
hwin.R.Midway <- ets(train.Midway)
summary(hwin.R.Midway)
hwin.R.Midway.pred <- forecast(hwin.R.Midway, h=nValid, level=0)
```

```{r}
plot(poly_season_Midway_pred, include = 12, main = "Comparing ARIMA")
lines(hwin.pred2$mean, col = 'purple', lwd = 2)                 
lines(snaive_Midway_pred$mean, col = 'green', lwd=2)
lines(arima.Midway.pred$mean, col = 'pink', lwd=2)
lines(valid.Midway, lwd =2)
legend("topleft", legend = c("Actual","HW", "Naive", "ARIMA", "Poly"),
       col = c("black", "purple", "green", "pink", "blue"), lty = c(1, 1, 1), lwd = c(1, 2, 1),  cex = 0.7)

```

From this plot, it appears that the Holt-Winter method continues to perform best on the Chicago Midway data. Again, like Chicago O'Hare, the ARIMA model is an improvement over the poly seasonal regression but does not appear to be as accurate as the Holt-Winter.

To prove this, lets compare all of the best methods from regression, smoothing, and ARIMA models by their accuracy to the benchmark seasonal naive method.

```{r}
accuracy(poly_season_Midway_pred$mean, valid.Midway) 
accuracy(hwin.pred2$mean, valid.Midway)                    ## Performs best
accuracy(arima.Midway.pred$mean, valid.Midway)         
accuracy(snaive_Midway_pred$mean, valid.Midway)
```

The accuracy function reinforces our finding that the Holt-Winter method is indeed the most effective method thus far on the Chicago Midway dataset. 

------------------------------------------------------------------------------------------------------------

## Bonus: Long Short-term Memory Model

LSTM stands for long short-term memory networks, used in the field of Deep Learning. It is a variety of recurrent neural networks (RNNs) that are capable of learning long-term dependencies, especially in sequence prediction problems. LSTM has feedback connections, i.e., it is capable of processing the entire sequence of data, apart from single data points such as time series.

**Let's predict delay rates of O'hare and Midway based on the LSTM.**

**Ohare** 

**Data Prep in Python**
```{python}
# Import data
import pandas as pd
#import os
import tensorflow as tf
import numpy as np
df = pd.read_csv("O'Hare_cleaned.csv")
df = df.iloc[: , 1:]
np.random.seed(7)

# Data clean and transform
df['Date'] = df.apply(lambda x: str(round(x['year'])) + '-' + str(round(x['Month'])), axis = 1)
df.index = pd.to_datetime(df['Date'], format='%Y-%m')
delay = df['Delayed (%)']
```

**Format Data**
```{python}
# Create the function to make our dataframe applicable to LSTM model in TensorFlow
def df_to_X_y(df, window_size=5):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
    row = [[a] for a in df_as_np[i:i+window_size]]
    X.append(row)
    label = df_as_np[i+window_size]
    y.append(label)
  return np.array(X), np.array(y)
```

```{python}
# Log transformation
delay_log = np.log(delay)
```

```{python}
#split the data into train and test
WINDOW_SIZE = 2
X1, y1 = df_to_X_y(delay_log, WINDOW_SIZE)
X1.shape, y1.shape
```

```{python}
X_train1, y_train1 = X1[:105], y1[:105]
X_test1, y_test1 = X1[105:], y1[105:]
```

**Model Building**
```{python}
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import *
from tensorflow.keras.callbacks import ModelCheckpoint
from tensorflow.keras.losses import MeanSquaredError
from tensorflow.keras.metrics import RootMeanSquaredError
from tensorflow.keras.optimizers import Adam

tf.random.set_seed(7)
model1 = Sequential()
model1.add(InputLayer((2, 1)))
model1.add(LSTM(64))
model1.add(Dense(8, 'relu'))
model1.add(Dense(1, 'linear'))

model1.summary()
```

```{python}
tf.random.set_seed(7)
cp1 = ModelCheckpoint('model1/', save_best_only=True)
model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[RootMeanSquaredError()])
```

```{python}
tf.random.set_seed(7)
model1.fit(X_train1, y_train1, epochs=10, validation_data= (X_test1,y_test1), callbacks=[cp1])
```

```{python}
# show the performance in train data
train_predictions = np.exp(model1.predict(X_train1).flatten())
train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':np.exp(y_train1)})
train_results
```

```{python}
import matplotlib.pyplot as plt
plt.plot(train_results['Train Predictions'])
plt.plot(train_results['Actuals'])
```

```{python}
#show the performance in test data
test_predictions = np.exp(model1.predict(X_test1).flatten())
test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':np.exp(y_test1)})
test_results
```

```{python}
plt.plot(test_results['Test Predictions'])
plt.plot(test_results['Actuals'])
```

```{python}
#**Note that results may sightly change every time you run.
mse = np.mean((test_results['Actuals'] - test_results['Test Predictions']) ** 2)
rmse = np.sqrt(mse)
mae = np.mean(np.abs(test_results['Actuals'] - test_results['Test Predictions']))
mpe = np.mean((test_results['Actuals'] - test_results['Test Predictions']) / test_results['Actuals']) * 100
mape = np.mean(np.abs((test_results['Actuals'] - test_results['Test Predictions']) / test_results['Actuals'])) * 100

print('RMSE:', round(rmse,2))
print('MAE:', round(mae,2))
print('MPE:', round(mpe,2))
print('MAPE:', round(mape,2))
```


**Midway**
Then we do the same for Midway.

*Data Preparation**
```{python}
df = pd.read_csv("Midway_cleaned.csv")
df = df.iloc[: , 1:]
```

```{python}
df['Date'] = df.apply(lambda x: str(round(x['year'])) + '-' + str(round(x['Month'])), axis = 1)
```

```{python}
df.index = pd.to_datetime(df['Date'], format='%Y-%m')
delay = df['Delayed (%)']
```

**Format Data**
```{python}
def df_to_X_y(df, window_size=5):
  df_as_np = df.to_numpy()
  X = []
  y = []
  for i in range(len(df_as_np)-window_size):
    row = [[a] for a in df_as_np[i:i+window_size]]
    X.append(row)
    label = df_as_np[i+window_size]
    y.append(label)
  return np.array(X), np.array(y)
```

```{python}
delay_log = np.log(delay)
```

```{python}
WINDOW_SIZE = 2
X1, y1 = df_to_X_y(delay_log, WINDOW_SIZE)
X1.shape, y1.shape
```

```{python}
X_train1, y_train1 = X1[:105], y1[:105]

X_test1, y_test1 = X1[105:], y1[105:]
```

**Model Building**
```{python}
tf.random.set_seed(7)

model1 = Sequential()
model1.add(InputLayer((2, 1)))
model1.add(LSTM(64))
model1.add(Dense(8, 'relu'))
model1.add(Dense(1, 'linear'))

model1.summary()
```

```{python}
tf.random.set_seed(7)
cp1 = ModelCheckpoint('model1/', save_best_only=True)
model1.compile(loss=MeanSquaredError(), optimizer=Adam(learning_rate=0.01), metrics=[RootMeanSquaredError()])
```

```{python}
tf.random.set_seed(7)
model1.fit(X_train1, y_train1, epochs=10, validation_data= (X_test1,y_test1), callbacks=[cp1])
```

```{python}
train_predictions = np.exp(model1.predict(X_train1).flatten())
train_results = pd.DataFrame(data={'Train Predictions':train_predictions, 'Actuals':np.exp(y_train1)})
train_results
```

```{python}
import matplotlib.pyplot as plt
plt.plot(train_results['Train Predictions'])
plt.plot(train_results['Actuals'])
```

```{python}
test_predictions = np.exp(model1.predict(X_test1).flatten())
test_results = pd.DataFrame(data={'Test Predictions':test_predictions, 'Actuals':np.exp(y_test1)})
test_results
```

```{python}
plt.plot(test_results['Test Predictions'])
plt.plot(test_results['Actuals'])
```

```{python}
#**Note that results may sightly change every time you run.
mse = np.mean((test_results['Actuals'] - test_results['Test Predictions']) ** 2)
rmse = np.sqrt(mse)
mae = np.mean(np.abs(test_results['Actuals'] - test_results['Test Predictions']))
mpe = np.mean((test_results['Actuals'] - test_results['Test Predictions']) / test_results['Actuals']) * 100
mape = np.mean(np.abs((test_results['Actuals'] - test_results['Test Predictions']) / test_results['Actuals'])) * 100

print('RMSE:', round(rmse,2))
print('MAE:', round(mae,2))
print('MPE:', round(mpe,2))
print('MAPE:', round(mape,2))
```


---------------------------------------------------------------------------------------------------------------

## Forecast Future Delayed Departures ## 

Finally, lets use the models that performed best on our validation data to create forecasts for estimated future delayed departure percentages for the two Chicago airports for the next 12 months.

First, let's forecast the next 12 months for Chicago O'Hare using the ETS(AAA) method.
```{r}
ets.aaa.Future <- ets(Ohare.ts, model = 'AAA')
ets.aaa.Future.pred <- forecast(ets.aaa.Future, h=nValid, level = 0)
plot(ets.aaa.Future.pred, include = 12)
lines(Ohare.ts)

ets.aaa.Future.pred$mean
```

Next, let's forecast the next 12 months for Chicago Midway using the ETS(ANA) method.
```{r}
ets.hw.Future <- ets(Midway.ts, model = 'ANA')
ets.hw.Future.pred <- forecast(ets.hw.Future, h=nValid, level = 0)
plot(ets.hw.Future.pred, include = 12)
lines(Midway.ts)

ets.hw.Future.pred$mean
```
